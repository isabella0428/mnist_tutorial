{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a popular deep learning framework and it's easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import time\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the mnist data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the model, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class Lenet(nn.Module):\n",
    "    # Define model\n",
    "    def __init__(self):\n",
    "        super(Lenet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, stride=1,padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolution\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Full connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "model = Lenet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch:0 loss:479.659077167511 train accuracy:0.6756\n",
      "Test loss:12.629231452941895 test accuracy:0.9479\n",
      "Training Epoch:1 loss:55.733505349606276 train accuracy:0.9620833333333333\n",
      "Test loss:5.43077278137207 test accuracy:0.9759\n",
      "Training Epoch:2 loss:36.155685756355524 train accuracy:0.9739333333333333\n",
      "Test loss:4.428620338439941 test accuracy:0.9812\n",
      "Training Epoch:3 loss:27.769600056111813 train accuracy:0.98\n",
      "Test loss:3.7956814765930176 test accuracy:0.9822\n",
      "Training Epoch:4 loss:22.827697901055217 train accuracy:0.9834166666666667\n",
      "Test loss:3.30773663520813 test accuracy:0.9853\n",
      "Training Epoch:5 loss:19.558279015123844 train accuracy:0.9855666666666667\n",
      "Test loss:3.0008373260498047 test accuracy:0.986\n",
      "Training Epoch:6 loss:16.829195016995072 train accuracy:0.9869666666666667\n",
      "Test loss:3.0981287956237793 test accuracy:0.9845\n",
      "Training Epoch:7 loss:14.52556836232543 train accuracy:0.9885833333333334\n",
      "Test loss:2.5836009979248047 test accuracy:0.9874\n",
      "Training Epoch:8 loss:12.998861839994788 train accuracy:0.9894166666666667\n",
      "Test loss:2.6043832302093506 test accuracy:0.987\n",
      "Training Epoch:9 loss:11.775452807545662 train accuracy:0.9905\n",
      "Test loss:2.355299472808838 test accuracy:0.9887\n",
      "Training Epoch:10 loss:10.249378435313702 train accuracy:0.9911166666666666\n",
      "Test loss:2.4302821159362793 test accuracy:0.9879\n",
      "Training Epoch:11 loss:9.415237285196781 train accuracy:0.9920333333333333\n",
      "Test loss:3.028146743774414 test accuracy:0.9856\n",
      "Training Epoch:12 loss:8.318682786077261 train accuracy:0.9928333333333333\n",
      "Test loss:2.6141951084136963 test accuracy:0.9878\n",
      "Training Epoch:13 loss:7.232901856303215 train accuracy:0.9935333333333334\n",
      "Test loss:2.386129379272461 test accuracy:0.9871\n",
      "Training Epoch:14 loss:6.590057238936424 train accuracy:0.9940666666666667\n",
      "Test loss:2.443796396255493 test accuracy:0.9888\n",
      "Training Epoch:15 loss:6.012018581852317 train accuracy:0.99435\n",
      "Test loss:3.038846015930176 test accuracy:0.9871\n",
      "Training Epoch:16 loss:5.438618190586567 train accuracy:0.9948\n",
      "Test loss:2.4531381130218506 test accuracy:0.9884\n",
      "Training Epoch:17 loss:4.525867708027363 train accuracy:0.9956333333333334\n",
      "Test loss:3.7933144569396973 test accuracy:0.9839\n",
      "Training Epoch:18 loss:4.088975831866264 train accuracy:0.9959333333333333\n",
      "Test loss:2.2316081523895264 test accuracy:0.9889\n",
      "Training Epoch:19 loss:3.839456833899021 train accuracy:0.9962666666666666\n",
      "Test loss:2.2035748958587646 test accuracy:0.9893\n",
      "Training Epoch:20 loss:3.2145558893680573 train accuracy:0.9965\n",
      "Test loss:2.6582353115081787 test accuracy:0.9884\n",
      "Training Epoch:21 loss:3.0850928649306297 train accuracy:0.9963833333333333\n",
      "Test loss:2.4970345497131348 test accuracy:0.9893\n",
      "Training Epoch:22 loss:2.6702789831906557 train accuracy:0.9968\n",
      "Test loss:2.629838466644287 test accuracy:0.9882\n",
      "Training Epoch:23 loss:2.6831894665956497 train accuracy:0.9968\n",
      "Test loss:2.68084716796875 test accuracy:0.9888\n",
      "Training Epoch:24 loss:2.2750228345394135 train accuracy:0.9972166666666666\n",
      "Test loss:2.6023826599121094 test accuracy:0.9883\n",
      "Training Epoch:25 loss:1.9659757055342197 train accuracy:0.9972666666666666\n",
      "Test loss:2.5906054973602295 test accuracy:0.9886\n",
      "Training Epoch:26 loss:1.6551733016967773 train accuracy:0.9975833333333334\n",
      "Test loss:3.567033529281616 test accuracy:0.985\n",
      "Training Epoch:27 loss:1.2951942719519138 train accuracy:0.9978833333333333\n",
      "Test loss:2.6384847164154053 test accuracy:0.9884\n",
      "Training Epoch:28 loss:1.0643605031073093 train accuracy:0.9979833333333333\n",
      "Test loss:2.750580310821533 test accuracy:0.9889\n",
      "Training Epoch:29 loss:0.8755937106907368 train accuracy:0.9981\n",
      "Test loss:2.6472134590148926 test accuracy:0.989\n",
      "Training Epoch:30 loss:0.8894379548728466 train accuracy:0.9979833333333333\n",
      "Test loss:2.65321683883667 test accuracy:0.9885\n",
      "Training Epoch:31 loss:0.8450346775352955 train accuracy:0.9980333333333333\n",
      "Test loss:2.7637858390808105 test accuracy:0.989\n",
      "Training Epoch:32 loss:0.7605298273265362 train accuracy:0.9980333333333333\n",
      "Test loss:2.6574923992156982 test accuracy:0.9888\n",
      "Training Epoch:33 loss:0.6586904153227806 train accuracy:0.9981666666666666\n",
      "Test loss:2.8475749492645264 test accuracy:0.9884\n",
      "Training Epoch:34 loss:0.6294547580182552 train accuracy:0.9981166666666667\n",
      "Test loss:2.7550411224365234 test accuracy:0.9887\n",
      "Training Epoch:35 loss:0.5797044485807419 train accuracy:0.9982\n",
      "Test loss:2.963545560836792 test accuracy:0.9883\n",
      "Training Epoch:36 loss:0.5730295665562153 train accuracy:0.9982\n",
      "Test loss:2.8186347484588623 test accuracy:0.9888\n",
      "Training Epoch:37 loss:0.4102889224886894 train accuracy:0.9983\n",
      "Test loss:2.845414161682129 test accuracy:0.9889\n",
      "Training Epoch:38 loss:0.4023417532444 train accuracy:0.9982666666666666\n",
      "Test loss:2.9010519981384277 test accuracy:0.9886\n",
      "Training Epoch:39 loss:0.32247259840369225 train accuracy:0.9983166666666666\n",
      "Test loss:2.889475107192993 test accuracy:0.989\n",
      "Training Epoch:40 loss:0.295298770070076 train accuracy:0.9983333333333333\n",
      "Test loss:2.8829381465911865 test accuracy:0.9884\n",
      "Training Epoch:41 loss:0.29940787702798843 train accuracy:0.9983166666666666\n",
      "Test loss:2.9689507484436035 test accuracy:0.9887\n",
      "Training Epoch:42 loss:0.2529212720692158 train accuracy:0.9983666666666666\n",
      "Test loss:3.0141830444335938 test accuracy:0.9889\n",
      "Training Epoch:43 loss:0.2548781894147396 train accuracy:0.9983333333333333\n",
      "Test loss:2.9565513134002686 test accuracy:0.9891\n",
      "Training Epoch:44 loss:0.24481231346726418 train accuracy:0.9983166666666666\n",
      "Test loss:3.0914103984832764 test accuracy:0.9889\n",
      "Training Epoch:45 loss:0.24162419140338898 train accuracy:0.9983666666666666\n",
      "Test loss:3.0222160816192627 test accuracy:0.9884\n",
      "Training Epoch:46 loss:0.21786539256572723 train accuracy:0.9983333333333333\n",
      "Test loss:3.027255058288574 test accuracy:0.989\n",
      "Training Epoch:47 loss:0.21773559227585793 train accuracy:0.9983166666666666\n",
      "Test loss:3.056124687194824 test accuracy:0.9887\n",
      "Training Epoch:48 loss:0.19098351523280144 train accuracy:0.99835\n",
      "Test loss:3.1454105377197266 test accuracy:0.989\n",
      "Training Epoch:49 loss:0.17482351139187813 train accuracy:0.9983833333333333\n",
      "Test loss:3.1076254844665527 test accuracy:0.9888\n",
      "Training Epoch:50 loss:0.1545141115784645 train accuracy:0.9983833333333333\n",
      "Test loss:3.1047916412353516 test accuracy:0.9891\n",
      "Training Epoch:51 loss:0.14723198860883713 train accuracy:0.9983833333333333\n",
      "Test loss:3.1512742042541504 test accuracy:0.9887\n",
      "Training Epoch:52 loss:0.1403220184147358 train accuracy:0.9983833333333333\n",
      "Test loss:3.1659600734710693 test accuracy:0.9886\n",
      "Training Epoch:53 loss:0.1367185115814209 train accuracy:0.9983666666666666\n",
      "Test loss:3.2685022354125977 test accuracy:0.9883\n",
      "Training Epoch:54 loss:0.14034853875637054 train accuracy:0.9983666666666666\n",
      "Test loss:3.1767969131469727 test accuracy:0.9889\n",
      "Training Epoch:55 loss:0.13947241008281708 train accuracy:0.9983833333333333\n",
      "Test loss:3.1714296340942383 test accuracy:0.9889\n",
      "Training Epoch:56 loss:0.11796088144183159 train accuracy:0.9983833333333333\n",
      "Test loss:3.197744131088257 test accuracy:0.9889\n",
      "Training Epoch:57 loss:0.11917589232325554 train accuracy:0.9983833333333333\n",
      "Test loss:3.212728261947632 test accuracy:0.989\n",
      "Training Epoch:58 loss:0.1112712174654007 train accuracy:0.9983833333333333\n",
      "Test loss:3.231318712234497 test accuracy:0.989\n",
      "Training Epoch:59 loss:0.11355002224445343 train accuracy:0.9983833333333333\n",
      "Test loss:3.2639458179473877 test accuracy:0.9887\n",
      "Training Epoch:60 loss:0.10625408589839935 train accuracy:0.9983833333333333\n",
      "Test loss:3.2560455799102783 test accuracy:0.9892\n",
      "Training Epoch:61 loss:0.10053306072950363 train accuracy:0.9983833333333333\n",
      "Test loss:3.278057813644409 test accuracy:0.9889\n",
      "Training Epoch:62 loss:0.09574997052550316 train accuracy:0.9983833333333333\n",
      "Test loss:3.285499095916748 test accuracy:0.9888\n",
      "Training Epoch:63 loss:0.09402075782418251 train accuracy:0.9983833333333333\n",
      "Test loss:3.2992990016937256 test accuracy:0.9893\n",
      "Training Epoch:64 loss:0.08904740586876869 train accuracy:0.9983833333333333\n",
      "Test loss:3.302839756011963 test accuracy:0.9889\n",
      "Training Epoch:65 loss:0.09025198966264725 train accuracy:0.9983833333333333\n",
      "Test loss:3.3246421813964844 test accuracy:0.9891\n",
      "Training Epoch:66 loss:0.08875300921499729 train accuracy:0.9983833333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:3.3473353385925293 test accuracy:0.9887\n",
      "Training Epoch:67 loss:0.08440062031149864 train accuracy:0.9983833333333333\n",
      "Test loss:3.348032236099243 test accuracy:0.9889\n",
      "Training Epoch:68 loss:0.0789526216685772 train accuracy:0.9983833333333333\n",
      "Test loss:3.3507893085479736 test accuracy:0.989\n",
      "Training Epoch:69 loss:0.08016923069953918 train accuracy:0.9983833333333333\n",
      "Test loss:3.3764171600341797 test accuracy:0.9887\n",
      "Training Epoch:70 loss:0.07546404376626015 train accuracy:0.9983833333333333\n",
      "Test loss:3.3739097118377686 test accuracy:0.9891\n",
      "Training Epoch:71 loss:0.07455017045140266 train accuracy:0.9983833333333333\n",
      "Test loss:3.389232635498047 test accuracy:0.9889\n",
      "Training Epoch:72 loss:0.07177343219518661 train accuracy:0.9983833333333333\n",
      "Test loss:3.413372278213501 test accuracy:0.989\n",
      "Training Epoch:73 loss:0.07116541638970375 train accuracy:0.9983833333333333\n",
      "Test loss:3.4159634113311768 test accuracy:0.989\n",
      "Training Epoch:74 loss:0.06934407725930214 train accuracy:0.9983833333333333\n",
      "Test loss:3.4139437675476074 test accuracy:0.989\n",
      "Training Epoch:75 loss:0.06763228215277195 train accuracy:0.9983833333333333\n",
      "Test loss:3.4049153327941895 test accuracy:0.9893\n",
      "Training Epoch:76 loss:0.06638394482433796 train accuracy:0.9983833333333333\n",
      "Test loss:3.433964490890503 test accuracy:0.989\n",
      "Training Epoch:77 loss:0.06368828564882278 train accuracy:0.9983833333333333\n",
      "Test loss:3.4494991302490234 test accuracy:0.9891\n",
      "Training Epoch:78 loss:0.06261218897998333 train accuracy:0.9983833333333333\n",
      "Test loss:3.4505951404571533 test accuracy:0.9891\n",
      "Training Epoch:79 loss:0.0619044303894043 train accuracy:0.9983833333333333\n",
      "Test loss:3.448676824569702 test accuracy:0.9891\n",
      "Training Epoch:80 loss:0.060102617368102074 train accuracy:0.9983833333333333\n",
      "Test loss:3.467747211456299 test accuracy:0.9891\n",
      "Training Epoch:81 loss:0.05917805805802345 train accuracy:0.9983833333333333\n",
      "Test loss:3.486905574798584 test accuracy:0.989\n",
      "Training Epoch:82 loss:0.05771009251475334 train accuracy:0.9983833333333333\n",
      "Test loss:3.477071523666382 test accuracy:0.9894\n",
      "Training Epoch:83 loss:0.056745827198028564 train accuracy:0.9983833333333333\n",
      "Test loss:3.5043179988861084 test accuracy:0.9888\n",
      "Training Epoch:84 loss:0.055737970396876335 train accuracy:0.9983833333333333\n",
      "Test loss:3.5139222145080566 test accuracy:0.9889\n",
      "Training Epoch:85 loss:0.05364494025707245 train accuracy:0.9983833333333333\n",
      "Test loss:3.535055637359619 test accuracy:0.9889\n",
      "Training Epoch:86 loss:0.05468111112713814 train accuracy:0.9983833333333333\n",
      "Test loss:3.522254467010498 test accuracy:0.9891\n",
      "Training Epoch:87 loss:0.053235484287142754 train accuracy:0.9983833333333333\n",
      "Test loss:3.531402826309204 test accuracy:0.9892\n",
      "Training Epoch:88 loss:0.05167696624994278 train accuracy:0.9983833333333333\n",
      "Test loss:3.5417041778564453 test accuracy:0.989\n",
      "Training Epoch:89 loss:0.05152720957994461 train accuracy:0.9983833333333333\n",
      "Test loss:3.549906015396118 test accuracy:0.9894\n",
      "Training Epoch:90 loss:0.050716765224933624 train accuracy:0.9983833333333333\n",
      "Test loss:3.5571703910827637 test accuracy:0.9891\n",
      "Training Epoch:91 loss:0.049110667780041695 train accuracy:0.9983833333333333\n",
      "Test loss:3.5588159561157227 test accuracy:0.9893\n",
      "Training Epoch:92 loss:0.04803389124572277 train accuracy:0.9983833333333333\n",
      "Test loss:3.576385021209717 test accuracy:0.9888\n",
      "Training Epoch:93 loss:0.048471247777342796 train accuracy:0.9983833333333333\n",
      "Test loss:3.595088005065918 test accuracy:0.9891\n",
      "Training Epoch:94 loss:0.048401305451989174 train accuracy:0.9983833333333333\n",
      "Test loss:3.5817840099334717 test accuracy:0.9889\n",
      "Training Epoch:95 loss:0.046566711738705635 train accuracy:0.9983833333333333\n",
      "Test loss:3.6199324131011963 test accuracy:0.9888\n",
      "Training Epoch:96 loss:0.046241067349910736 train accuracy:0.9983833333333333\n",
      "Test loss:3.6090142726898193 test accuracy:0.9891\n",
      "Training Epoch:97 loss:0.04719160310924053 train accuracy:0.9983833333333333\n",
      "Test loss:3.614596128463745 test accuracy:0.9891\n",
      "Training Epoch:98 loss:0.045550381764769554 train accuracy:0.9983833333333333\n",
      "Test loss:3.6147148609161377 test accuracy:0.9892\n",
      "Training Epoch:99 loss:0.04490966722369194 train accuracy:0.9983833333333333\n",
      "Test loss:3.6326451301574707 test accuracy:0.9889\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train_model(model, optimizer, criterion, epoch):\n",
    "    model = model.cuda()\n",
    "\n",
    "    # train and evaluate\n",
    "    train_loss = 0\n",
    "    correct_pred = 0\n",
    "    for batchidx, (datas, labels) in enumerate(train_loader):\n",
    "        # zero the parameter gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # load the data into cuda\n",
    "        datas, labels = datas.cuda(), labels.cuda()\n",
    "        datas, labels = Variable(datas), Variable(labels)\n",
    "\n",
    "        # Forward, backward, optimize\n",
    "        out = model(datas)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred = out.argmax(dim=1, keepdim=True)\n",
    "        correct_pred += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "    train_accuracy = correct_pred/len(train_dataset)\n",
    "    # Print training result\n",
    "    print(\"Training Epoch:{} loss:{} train accuracy:{}\".format(\n",
    "        epoch, train_loss, train_accuracy))\n",
    "    return train_accuracy\n",
    "\n",
    "def test_model(model):\n",
    "    # evaluate\n",
    "    correct_test = 0\n",
    "    test_loss = 0\n",
    "    for batchidx, (datas, labels) in enumerate(test_loader):\n",
    "        datas, labels = datas.cuda(), labels.cuda()\n",
    "        out = model(datas)\n",
    "        test_loss += criterion(out, labels)\n",
    "        pred = out.argmax(dim=1, keepdim=True)\n",
    "        correct_test += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_accuracy = correct_test/len(test_dataset)\n",
    "    print(\"Test loss:{} test accuracy:{}\".format(\n",
    "        test_loss, test_accuracy))\n",
    "    return test_accuracy\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    model = Lenet()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.07)\n",
    "    \n",
    "    for i in range(NUM_EPOCHS):\n",
    "        train_accuracy = train_model(model, optimizer, criterion, i)\n",
    "        test_accuracy  = test_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5:\n",
    "Please print the training and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.9983833333333333\n",
      "test loss: 0.9889\n"
     ]
    }
   ],
   "source": [
    "print(\"train loss: {}\".format(train_accuracy))\n",
    "print(\"test loss: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
